{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f182096f-145f-4653-9b74-482296c6cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV library for image processing\n",
    "import mediapipe as mp  # MediaPipe library for hand tracking\n",
    "import pyautogui  # PyAutoGUI library for controlling the mouse cursor\n",
    "\n",
    "class HandDetector:\n",
    "    def __init__(self, static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5):\n",
    "        # Initialise HandDetector object with parameters for hand tracking\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(static_image_mode=static_image_mode, max_num_hands=max_num_hands,\n",
    "                                          min_detection_confidence=min_detection_confidence,\n",
    "                                          min_tracking_confidence=min_tracking_confidence)\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    def detect_landmarks(self, frame):\n",
    "        # Convert BGR frame to RGB for compatibility with MediaPipe\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Process the frame to detect hand landmarks\n",
    "        results = self.hands.process(image_rgb)\n",
    "        landmarks = []\n",
    "        if results.multi_hand_landmarks:\n",
    "            # Select the hand with the highest confidence score\n",
    "            max_confidence_hand = max(results.multi_handedness, key=lambda x: x.classification[0].score)\n",
    "            max_confidence_index = results.multi_handedness.index(max_confidence_hand)\n",
    "            hand_landmarks = results.multi_hand_landmarks[max_confidence_index]\n",
    "            landmarks.append(hand_landmarks.landmark)\n",
    "            # Draw hand landmarks on the frame\n",
    "            self.mp_drawing.draw_landmarks(frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)\n",
    "        return frame, landmarks\n",
    "\n",
    "class CursorController:\n",
    "    def __init__(self, screen_width, screen_height):\n",
    "        # Initialise CursorController object with screen dimensions\n",
    "        self.screen_width = screen_width\n",
    "        self.screen_height = screen_height\n",
    "        self.is_fist = False\n",
    "        self.is_middle_finger = False\n",
    "\n",
    "    def move_cursor(self, x, y):\n",
    "        # Move the cursor to the target position based on hand gestures\n",
    "        target_x = int((1 - x) * self.screen_width)  # Invert x-axis as this was going the wrong way\n",
    "        target_y = int(y * self.screen_height)\n",
    "        pyautogui.moveTo(target_x, target_y)\n",
    "\n",
    "    # Functions to simulate mouse actions\n",
    "    def click(self):\n",
    "        pyautogui.mouseDown()\n",
    "\n",
    "    def release_click(self):\n",
    "        pyautogui.mouseUp()\n",
    "\n",
    "    def right_click(self):\n",
    "        pyautogui.mouseDown(button='right')\n",
    "\n",
    "    def release_right_click(self):\n",
    "        pyautogui.mouseUp(button='right')\n",
    "\n",
    "    def double_click(self):\n",
    "        pyautogui.doubleClick()\n",
    "\n",
    "def main():\n",
    "    # Initialise video capture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # Get screen resolution\n",
    "    screen_width = pyautogui.size().width\n",
    "    screen_height = pyautogui.size().height\n",
    "    # Initialise HandDetector and CursorController objects\n",
    "    hand_detector = HandDetector()\n",
    "    cursor_controller = CursorController(screen_width, screen_height)\n",
    "\n",
    "    # Define distance variables outside the loop\n",
    "    distance_thumb_index = 0\n",
    "    distance_thumb_middle = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Read frame from video capture\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect hand landmarks in the frame\n",
    "        frame, landmarks = hand_detector.detect_landmarks(frame)\n",
    "\n",
    "        # Add text instructions to the frame\n",
    "        cv2.putText(frame, \"PINCH INDEX TO THUMB TO LEFT CLICK\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, \"MIDDLE TO THUMB TO RIGHT CLICK\", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, \"CROSS INDEX IN FRONT OF MIDDLE TO DOUBLE CLICK\", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        if landmarks:\n",
    "            thumb_tip = (landmarks[0][4].x, landmarks[0][4].y)\n",
    "            index_tip = (landmarks[0][8].x, landmarks[0][8].y)\n",
    "            middle_tip = (landmarks[0][12].x, landmarks[0][12].y)\n",
    "            distance_thumb_index = ((thumb_tip[0] - index_tip[0])**2 + (thumb_tip[1] - index_tip[1])**2) ** 0.5\n",
    "            distance_thumb_middle = ((thumb_tip[0] - middle_tip[0])**2 + (thumb_tip[1] - middle_tip[1])**2) ** 0.5\n",
    "            \n",
    "            # Double click detection: if index and middle fingers are close together\n",
    "            distance_index_middle = ((index_tip[0] - middle_tip[0])**2 + (index_tip[1] - middle_tip[1])**2) ** 0.5\n",
    "            # Threshold for double click\n",
    "            double_click_threshold = 0.03\n",
    "\n",
    "            # Left click action\n",
    "            if distance_thumb_index < 0.05:\n",
    "                if not cursor_controller.is_fist:\n",
    "                    cursor_controller.click()\n",
    "                    cursor_controller.is_fist = True\n",
    "            else:\n",
    "                if cursor_controller.is_fist:\n",
    "                    cursor_controller.release_click()\n",
    "                    cursor_controller.is_fist = False\n",
    "\n",
    "            # Right click action\n",
    "            if distance_thumb_middle < 0.05:\n",
    "                if not cursor_controller.is_middle_finger:\n",
    "                    cursor_controller.right_click()\n",
    "                    cursor_controller.is_middle_finger = True\n",
    "            else:\n",
    "                if cursor_controller.is_middle_finger:\n",
    "                    cursor_controller.release_right_click()\n",
    "                    cursor_controller.is_middle_finger = False\n",
    "\n",
    "            # Double click action\n",
    "            if distance_index_middle < double_click_threshold:\n",
    "                cursor_controller.double_click()\n",
    "\n",
    "            palm_center = (landmarks[0][0].x, landmarks[0][0].y)  # Assuming the first landmark is the palm center.\n",
    "            cursor_controller.move_cursor(palm_center[0], palm_center[1])\n",
    "\n",
    "        # Display frame with hand landmarks\n",
    "        cv2.imshow('Hand Tracking', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release video capture object and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc0805-fac8-4bc5-a30a-137245727df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
